---
title: "coding_Ruiqi"
author: "Ruiqi Yan (ry2417)"
date: "4/20/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
library(ggplot2)
library(maps)
library(data.table)
library(tidyverse)
library(foreach)
library(doParallel)
library(MASS)
theme_set(theme(legend.position = "bottom"))
```

# Hurrican Data
hurricane703.csv collected the track data of 703 hurricanes in  the North Atlantic area since 1950. For all the storms, their location (longitude \& latitude) and maximum wind speed were recorded every 6 hours. The data includes the following variables 

1. **ID**:  ID of the hurricanes
2. **Season**: In which \textbf{year} the hurricane occurred 
3. **Month**: In which \textbf{month} the hurricane occurred 
4. **Nature**:  Nature of the hurricane 
  + ET: Extra Tropical
  + DS: Disturbance
  + NR: Not Rated
  + SS: Sub Tropical
  + TS: Tropical Storm
5. **time**: dates and time of the record  
6. **Latitude** and **Longitude**:  The location of  a hurricane check point 
7. **Wind.kt**  Maximum wind speed (in Knot) at each check point 

## load and clean data

```{r}
load("df_rm.RData")
## create variables of interest
dt = df_rm %>% 
  janitor::clean_names() %>% 
  group_by(id) %>% 
  mutate(wind_lag = lag(wind_kt,1), ##previous wind speed
         lat_shift = lag(latitude, 1) - lag(latitude, 2), ## change of lat
         long_shift = lag(longitude, 1) - lag(longitude, 2), ## change of long
         wind_shift = lag(wind_kt, 1) - lag(wind_kt, 2)) %>%  ##change of wind speed
  drop_na()

## group by hurricane and create design matrix for each hurricane
df_mcmc = dt %>% 
  dplyr::select(id,wind_kt,wind_lag,lat_shift, long_shift, wind_shift) %>% 
  nest(y = wind_kt, x_matrix=wind_lag:wind_shift) %>% 
  mutate(x_matrix = map(.x = x_matrix, ~model.matrix(~., data = .x)),
         y = map(y, pull))

y_obs = df_mcmc$y ## list of wind speed for each hurricane
x_matrix = df_mcmc$x_matrix ## list of design matrix for each hurricane
n_obs = nrow(dt) ## number of

## list of observation data: wind speed and design matrix
obs_list = list(y_obs = y_obs,
           x_matrix = x_matrix)

n_freq = dt %>% group_by(id) %>% count() %>% pull(n) ## number of obs for each hurricane
d = 5 ## dimension of beta_i
m = 681 ## number of hurricanes
n_beta = m*d ## total number of beta
n_theta = n_beta+d+1+15 ## total number of parameters
mu_ind = (n_beta+1):(n_beta+d)
sigma_ind = n_beta+d+1
cov_m_ind = (n_beta+d+2):n_theta
rep_time = rep(n_freq,d) ## repeat time for each beta
```

## part 1: log posterior functions

```{r}
## log posterior for beta of hurricane j
log_posterior_beta = function(beta, sigma, mu, sigma_p,j){
  x = obs_list$x_matrix[[j]]
  y = obs_list$y_obs[[j]]
  return(-t(y - x %*% beta) %*% (y - x %*% beta)/(2*sigma)-(1/2)*t(beta-mu)%*%sigma_p%*%(beta-mu))
}

## log posterior for sigma
log_posterior_sigma = function(beta_frame, sigma){
  ## make sure sigma is positive
  if(sigma <= 0){
    return(-Inf)
  } else{
    log_lik = -(n_obs/2)*log(sigma)-sum((dt$wind_kt-beta_frame[,1]-dt$wind_lag*beta_frame[,2]-dt$lat_shift*beta_frame[,3]-dt$long_shift*beta_frame[,4]-dt$wind_shift*beta_frame[,5])^2/(2*sigma))
    log_prior = -log(sigma)
    return(log_lik + log_prior)
  }
}
```

## part 2: mcmc algorithm

```{r}
blockwisemixedMH=function(a, theta_0, nrep=10000){
  theta = theta_0
  sigma_p = matrix(0,d,d)
  sigma_p[lower.tri(sigma_p, diag = TRUE)] = theta_0[cov_m_ind]
  sigma_p[upper.tri(sigma_p)] = t(sigma_p)[upper.tri(sigma_p)]
  theta_chain_mix = matrix(0, nrow = nrep, ncol = n_theta)
  for(i in 1:nrep){
    sigma_m = solve(sigma_p)
    # update beta by block of each hurricane
    for(j in 1:m){
      ind =  c(j, j+m, j+m*2, j+m*3, j+m*4)
      prop = theta
      prop[ind] = prop[ind]+2*(runif(5)-0.5)*a[1:5]
      if(log(runif(1)) < (log_posterior_beta(prop, sigma_p, j) - log_posterior_beta(theta, sigma_p, j))){
        theta[ind] = prop[ind]
      }
    }
    # update mu
    beta = matrix(theta[1:n_beta], nrow = d, byrow = T)
    beta_mean = rowMeans(beta)
    mu = mvrnorm(1,beta_mean,Sigma = sigma_m/m)
    theta[mu_ind] = mu
    # update sigma
    prop = theta
    prop[sigma_ind] = prop[sigma_ind]+2*(runif(1)-0.5)*a[6]
    if(log(runif(1)) < (log_posterior_sigma(prop) - log_posterior_sigma(theta))){
      theta[sigma_ind] = prop[sigma_ind]
    }
    # update inverse sigma matrix
    beta_mu = beta-mu
    S = solve(diag(d)+beta_mu%*%t(beta_mu))
    sigma_p = rWishart(1,df = 3*d+3+m,Sigma = S)
    sigma_p = apply(sigma_p,2,c)
    theta[cov_m_ind] = sigma_p[lower.tri(sigma_p, diag = T)]
    theta_chain_mix[i,] = theta
  }
  return(theta_chain_mix)
}

componentwisemixedMH=function(a, a_sigma, beta_0,sigma_0,cov_0, nrep=10000){
  sigma_p = cov_0
  beta = beta_0
  mu = colMeans(beta)
  sigma = sigma_0
  theta_chain_mix = matrix(0, nrow = nrep, ncol = n_theta)
  for(i in 1:nrep){
    sigma_m = solve(sigma_p)
    # update beta by block of each hurricane
    for(j in 1:m){
      for(k in 1:5){
        prop = beta[j,]
        prop[k] = prop[k]+2*(runif(1)-0.5)*a[(k-1)*681+j]
        if(log(runif(1)) < (log_posterior_beta(prop, sigma, mu, sigma_p,j) - log_posterior_beta(beta[j,], sigma, mu, sigma_p,j))){
          beta[j,k] = prop[k]
        }
      }
    }
    # update mu
    beta_mean = colMeans(beta)
    mu = mvrnorm(1,beta_mean,Sigma = sigma_m/m)
    # update sigma
    beta_frame = matrix(rep(c(beta),times = rep_time), ncol = d)
    prop = sigma
    prop = prop+2*(runif(1)-0.5)*a_sigma
    if(log(runif(1)) < (log_posterior_sigma(beta_frame, prop) - log_posterior_sigma(beta_frame, sigma))){
      sigma = prop
    }
    # update inverse sigma matrix
    beta_mu = t(beta)-mu
    S = solve(diag(d)+beta_mu%*%t(beta_mu))
    sigma_p = rWishart(1,df = 3*d+3+m,Sigma = S)
    sigma_p = apply(sigma_p,2,c)
    theta_chain_mix[i,] = c(c(beta),mu,sigma,sigma_p[lower.tri(sigma_p, diag = T)])
  }
  return(theta_chain_mix)
}

numCores <- detectCores()
registerDoParallel(numCores)
componentwisemixedMH_2=function(a, a_sigma, beta_0,sigma_0,cov_0, nrep=10000){
  sigma_p = cov_0
  beta = beta_0
  mu = colMeans(beta)
  sigma = sigma_0
  theta_chain_mix = matrix(0, nrow = nrep, ncol = n_theta)
  for(i in 1:nrep){
    sigma_m = solve(sigma_p)
    # update beta by block of each hurricane
    beta_new = foreach(j = 1:m, .combine = rbind) %dopar% {
      beta_j = beta[j,]
      for(k in 1:5){
        prop = beta_j
        prop[k] = prop[k]+2*(runif(1)-0.5)*a[(k-1)*681+j]
        if(log(runif(1)) < (log_posterior_beta(prop, sigma, mu, sigma_p,j) -
                            log_posterior_beta(beta[j,], sigma, mu, sigma_p,j))){
          beta_j[k] = prop[k]
          }
      }
      beta_j
    }
    beta = beta_new
    # update mu
    beta_mean = colMeans(beta)
    mu = mvrnorm(1,beta_mean,Sigma = sigma_m/m)
    # update sigma
    beta_frame = matrix(rep(c(beta),times = rep_time), ncol = d)
    prop = sigma
    prop = prop+2*(runif(1)-0.5)*a_sigma
    if(log(runif(1)) < (log_posterior_sigma(beta_frame, prop) - log_posterior_sigma(beta_frame, sigma))){
      sigma = prop
    }
    # update inverse sigma matrix
    beta_mu = t(beta)-mu
    S = solve(diag(d)+beta_mu%*%t(beta_mu))
    sigma_p = rWishart(1,df = 3*d+3+m,Sigma = S)
    sigma_p = apply(sigma_p,2,c)
    theta_chain_mix[i,] = c(c(beta),mu,sigma,sigma_p[lower.tri(sigma_p, diag = T)])
  }
  return(theta_chain_mix)
}


## calculate the number of unique value
numunique = function(x){length(unique(x))}

##
trace_inverse = function(x){
  m = matrix(0,5,5)
  m[lower.tri(m, diag = TRUE)] = x[cov_m_ind]
  m[upper.tri(m)] = t(m)[upper.tri(m)]
  return(sum(diag(m)))
}

```


## part 3: implement 10000 mcmc and get estimates

```{r}
## search window
ind_06 =  c(1,3,4,6,16,19,24,28,31,41,43,45,46,47,50,51,52,54,62,68,69,73,82,83,89,93:97,99,108,112,113,117:119, 121,122,125, 126,134,136,140,141,146,157, 158,163,182,206,217,225,239,249,250,255,261,263,274,282,297,306,310,315,332,333,335,344,345,355,357,371,372,381,397,399,400,403,404,412,415,416,418,421,427,431,433,436,439,442,445,448:450, 455,456,464,475,494,497,503,506,508,519,522:524,531,532,538,540,541,544,550,563,564,569,571,584,589,591,601,613,614,618,639,642,646,663,664)

ind_12 = c(8,13,38,57,63,64,66,72,80,84,114,115,137,145,149,159,164,165,186,196,204,207,218,223,234,236,238,243,246,251,254,260,266,268,275,283,288,290,291,294,307,323:326,330,334,336,354,368,370,377,378,380,387,395,398,401,428,429,432,437,454,457,458,460,469,480,482,487,488,491,495,499,504,510,517,526,527,534,537,539,545,547,551,570,572,575,583,595,596,599,602,603,609,610,612,619,624,630,634,637,640,641,648,660,665,666,671)

a2 = rep(0.08,m)
a2[ind_06] = 0.04
a2[ind_12] = 0.1
a3 = rep(1, m)
a3[203] = 0.8
a4 = rep(0.6,m)
a4[c(4,18,20,32,40,50,62,68,94,106,118,124,134,140,166,216,220,250,272,274,282,306,328,364, 376, 400, 412, 420, 434, 440, 442, 452, 456, 464, 508, 514, 522, 524, 562, 564, 568,584, 614, 642,646)] = 0.5

a5 = rep(0.3,m)
ind_14 = c(3,6,12,15,18,21,24,30,36,39,42 ,48, 57 ,63,66,72,75,78,81,84,87,93,102, 108,114,120,126,132,135,138,147,153,159,162,165,168,174,177,180,183,186,189,192,195,198,201,204,207,210,216,219,222,225,228,231,234,237,240,243,246,252,258,261,264,267,270,276,279,288,291,294,297,300,303,309,312,315,318,324,327,330,333,336, 339,342, 348, 351,354,357,360,363,366, 369, 372, 375, 378, 381, 387, 390, 393, 399, 402, 405, 408, 411, 417, 420, 423, 426, 429,432, 435,438, 441, 444, 447, 450, 453, 459, 462, 465, 468, 471, 474, 477, 480, 486, 489, 492, 495, 498, 501,504, 507, 510, 513, 525, 528, 534, 537, 540, 543, 546, 549, 555, 558, 564, 567, 570, 573,576, 579, 582, 585,588, 594, 600, 603, 606, 609, 612, 615, 624, 630, 633, 636, 639, 642,645, 648, 651, 654, 657, 660, 663, 666,669, 672, 675, 678, 681)
a5[ind_14] = 0.4
a = c(rep(1.1,m),a2,a3,a4,a5)
```



```{r}
## beta_i_0: MLR on ith hurricane and get the coefficient as beta_i_0
## mu_0: average over the beta_i_0 as the mu_0
## sigma_0: get the MSE of each MLR and take average as sigma_0
## sigma_m_0^-1: take the inverse of covariance matrix of beta_i_0 as the initial sigma_m_0^-1 

starting_beta = df_mcmc %>% 
  mutate(lm_fit = map2(.x = x_matrix, .y = y, ~lm(.y~.x[,-1], )),
         lm_0 = map_dbl(.x = lm_fit, ~coef(.x)[1]),
         lm_1 = map_dbl(.x = lm_fit, ~coef(.x)[2]),
         lm_2 = map_dbl(.x = lm_fit, ~coef(.x)[3]),
         lm_3 = map_dbl(.x = lm_fit, ~coef(.x)[4]),
         lm_4 = map_dbl(.x = lm_fit, ~coef(.x)[5]),
         sigma = map_dbl(.x = lm_fit, ~mean(.x$residuals^2))) %>% 
  ungroup() %>% 
  dplyr::select(lm_0:sigma)

sigma_0 = mean(starting_beta$sigma)

starting_beta = starting_beta%>%dplyr::select(-sigma) %>% as.matrix()
beta_0 = lm(wind_kt~wind_lag+lat_shift+long_shift+wind_shift, data = dt)
starting_beta[which(is.na(starting_beta[,2])),2] = coef(beta_0)[2]
starting_beta[which(is.na(starting_beta[,5])),5] = coef(beta_0)[5]

cov_0 = solve(cov(starting_beta))



```


```{r}
set.seed(1971)
theta_chain = componentwisemixedMH(a, a_sigma = 2, beta_0 = starting_beta, sigma_0, cov_0, nrep=10000)

## add colnames
names = c(str_c(rep(str_c("beta_", 0:4),each = m),"_", rep(1:m, d)),str_c("mu_", 0:4),"sigma")
for(i in 0:4){for(j in i:4){names = c(names, paste0("sigma_", i,j))}}
colnames(theta_chain) = names
## save results
save(theta_chain, file = "mcmc_chain.RData")

theta_chain_1 = theta_chain[1:1900,]
theta_chain_2 = theta_chain[1901:3600,]
theta_chain_3 = theta_chain[3601:5200,]
theta_chain_4 = theta_chain[5201:6800,]
theta_chain_5 = theta_chain[6801:8400,]
theta_chain_6 = theta_chain[8401:10000,]
save(theta_chain_1, file = "mcmc_chain_1.RData")
save(theta_chain_2, file = "mcmc_chain_2.RData")
save(theta_chain_3, file = "mcmc_chain_3.RData")
save(theta_chain_4, file = "mcmc_chain_4.RData")
save(theta_chain_5, file = "mcmc_chain_5.RData")
save(theta_chain_6, file = "mcmc_chain_6.RData")
theta_chain_df = as_tibble(theta_chain)
write_csv(theta_chain_df, file = "mcmc_chain.csv")
```

### acceptance rate

```{r}
load("mcmc_chain.RData")
## acceptance rate

a_rate = apply(theta_chain, MARGIN = 2, numunique)/10000

a_rate_matrix = matrix(a_rate[1:n_beta], ncol = 5)

a_0_range = range(a_rate_matrix[,1]) # search window 1.1
a_1_range = range(a_rate_matrix[,2]) # search window: 0.04-0.1
a_2_range = range(a_rate_matrix[,3]) # search window: 0.8-1
a_3_range = range(a_rate_matrix[,4]) # search window:0.5-0.6
a_4_range = range(a_rate_matrix[,5]) # search window: 0.4-0.5
a_sigma = a_rate[sigma_ind]

df_a = tibble(parameter = c("$\beta_0$", "$\beta_1$", "$\beta_2$", "$\beta_3$", "$\beta_4$", "$\sigma^2$"),
              search_window = c("1.1",
                                "0.04-0.1",
                                "0.8-1",
                                "0.5-0.6",
                                "0.4-0.5"),
              acceptance_rate = c(paste0(a_0_range[1],"-",a_0_range[2]),
                                  paste0(a_1_range[1],"-",a_1_range[2]),
                                  paste0(a_2_range[1],"-",a_2_range[2]),
                                  paste0(a_3_range[1],"-",a_3_range[2]),
                                  paste0(a_4_range[1],"-",a_4_range[2]),
                                  paste0(a_sigma)))
```

```{r}
theta_trace_inverse = apply(theta_chain, 1, trace_inverse)
par(mfrow=c(3,4))
plot(theta_chain[,3406], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,3407], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,3408], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,3409], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,3410], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,3411], type = "l")
abline(v = 5500, lty = 2)
plot(theta_trace_inverse, type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,2], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,m+2], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,m*2+2], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,m*3+2], type = "l")
abline(v = 5500, lty = 2)
plot(theta_chain[,m*4+2], type = "l")
abline(v = 5500, lty = 2)
```

### Estimates

```{r}
## take average as estimates
bs_estimates = unname(apply(theta_chain[5501:10000,], 2, mean))


inv_cov_m = matrix(0,5,5)
inv_cov_m[lower.tri(inv_cov_m, diag = TRUE)] = bs_estimates[cov_m_ind]
inv_cov_m[upper.tri(inv_cov_m)] = t(inv_cov_m)[upper.tri(inv_cov_m)]


cov_m = solve(inv_cov_m)

## estimates
sigma = bs_estimates[3411]
mu = bs_estimates[3406:3410]
beta = matrix(bs_estimates[1:n_beta], ncol = d)



```


## part 4: model performance

```{r}
dt_res = dt %>% 
  dplyr::select(id, nature, season, month, wind_kt,wind_lag,lat_shift, long_shift, wind_shift) %>%
  nest(data = nature:wind_shift) %>% 
  ungroup() %>% 
  mutate(beta_0 = beta[,1],
         beta_1 = beta[,2],
         beta_2 = beta[,3],
         beta_3 = beta[,4],
         beta_4 = beta[,5]) %>% 
  unnest(data) %>% 
  mutate(wind_kt_pred = beta_0+beta_1*wind_lag+beta_2*lat_shift+beta_3*long_shift+beta_4*wind_shift)

## adj r-square and r-square are 0.96
r_square = (1-sum((dt_res$wind_kt_pred-dt_res$wind_kt)^2)/sum((dt_res$wind_kt-mean(dt_res$wind_kt))^2))
p_value = 1-pchisq(sum((dt_res$wind_kt_pred-dt_res$wind_kt)^2)/sigma, n_obs-n_beta)
adj_r_square = 1-(1-r_square)*(n_obs-1)/(n_obs-n_beta)

## visualize some hurricane prediction

dt_res %>% filter(id %in% c("DOG.1950","BECKY.1958", "DORIS.1975","ANDREW.1986","FLORENCE.2000", "SANDY.2012")) %>%
  mutate(time = 1:n()) %>% 
  ggplot(aes(y = wind_kt, x = time))+
  geom_line(aes(color = "observation"))+
  geom_line(aes(y = wind_kt_pred, color = "prediction"))+
  scale_colour_manual(name = NULL,
values = c( "observation" = 1, "prediction" = 2))+
  facet_wrap(.~id, nrow = 2, scales = "free")+
  labs(x = "time",
       y = "wind speed",
       title = "Observed wind speed vs. Baysian model estimates")




```

